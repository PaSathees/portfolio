{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network with Numpy"
   ],
   "metadata": {
    "id": "-_HeYHqx8LzS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "id": "xKU7koUS8rFp"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Activations & Derivatives"
   ],
   "metadata": {
    "id": "rbZOm3YgHeyE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))"
   ],
   "metadata": {
    "id": "avr5H2SE8vLK"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def relu(x):\n",
    "  return np.maximum(0, x)"
   ],
   "metadata": {
    "id": "6uHe1dfdIky2"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weight initilaization"
   ],
   "metadata": {
    "id": "eaUUzbJHHR7U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# random seed\n",
    "np.random.seed(1)"
   ],
   "metadata": {
    "id": "XYCWW6b99EXA"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def initialize_weights_and_biases(X, out_layer=1, layers=[4, 4], p=False):\n",
    "  weights = []\n",
    "  biases = []\n",
    "\n",
    "  # order will follow layer 0 (input layer), weight 0, layer 1, weight 0, ...\n",
    "  # wights list will have weight 0, weight 1, ...\n",
    "\n",
    "  # initialize weights & biases randomly with mean 0\n",
    "  layer_0_weights = np.random.normal(0, 1/np.sqrt(X.shape[-1]), (X.shape[-1], layers[0]))\n",
    "  layer_n_weights = np.random.normal(0, 1/np.sqrt(layers[-1]), (layers[-1], out_layer))\n",
    "\n",
    "  layer_0_biases = np.zeros((1, layers[0]))\n",
    "  layer_n_biases = np.zeros((1, out_layer))\n",
    "\n",
    "  # add layer 0 weights\n",
    "  weights.append(layer_0_weights)\n",
    "  biases.append(layer_0_biases)\n",
    "\n",
    "  if len(layers) >= 2:\n",
    "    for num_layer in range(1, len(layers)):\n",
    "      # initialize weights randomly with mean 0\n",
    "      layer_weights = np.random.normal(0, 1/np.sqrt(layers[num_layer - 1]), (layers[num_layer - 1], layers[num_layer]))\n",
    "      layer_biases = np.zeros((1, layers[num_layer]))\n",
    "      weights.append(layer_weights)\n",
    "      biases.append(layer_biases)\n",
    "\n",
    "  weights.append(layer_n_weights)\n",
    "  biases.append(layer_n_biases)\n",
    "\n",
    "  if p:\n",
    "    print(\"Weights Shape\")\n",
    "\n",
    "    for weight in weights:\n",
    "      print(weight.shape)\n",
    "\n",
    "    print(\"-------\")\n",
    "    print(\"Biases Shape\")\n",
    "\n",
    "    for biase in biases:\n",
    "      print(biase.shape)\n",
    "\n",
    "  return weights, biases"
   ],
   "metadata": {
    "id": "MUAARgLY9Ojc"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weight initialization testing"
   ],
   "metadata": {
    "id": "v4IgsdzzHC6H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Input dataset\n",
    "X = np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "    \n",
    "# Output dataset            \n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])"
   ],
   "metadata": {
    "id": "9wq5Y4J3GeGP"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "weights, biases = initialize_weights_and_biases(X, layers=[4], p=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFlRvyIcGe8K",
    "outputId": "b3ef0a7f-4702-440d-886e-84f38651d111"
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Shape\n",
      "(3, 4)\n",
      "(4, 1)\n",
      "-------\n",
      "Biases Shape\n",
      "(1, 4)\n",
      "(1, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "weights, biases = initialize_weights_and_biases(X, layers=[4, 4], p=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "huqhfXkIAnlA",
    "outputId": "c6da3178-f5c4-4681-b4df-7aab4b8d72ab"
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Shape\n",
      "(3, 4)\n",
      "(4, 4)\n",
      "(4, 1)\n",
      "-------\n",
      "Biases Shape\n",
      "(1, 4)\n",
      "(1, 4)\n",
      "(1, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "weights, biases = initialize_weights_and_biases(X, layers=[4, 5, 4], p=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYDnXuPGBgsa",
    "outputId": "11d7c6e3-f76f-445d-8d8b-1b4a449a524f"
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Shape\n",
      "(3, 4)\n",
      "(4, 5)\n",
      "(5, 4)\n",
      "(4, 1)\n",
      "-------\n",
      "Biases Shape\n",
      "(1, 4)\n",
      "(1, 5)\n",
      "(1, 4)\n",
      "(1, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "id": "1A9MhIP3Hx3C"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Forward propagation"
   ],
   "metadata": {
    "id": "P-fNXDxkR6JU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def forward_prop(X, weights, biases):\n",
    "  # iterate over layers \n",
    "  activations = []\n",
    "\n",
    "  # first layer\n",
    "  z1 = np.dot(X, weights[0]) + biases[0]\n",
    "  activations.append(relu(z1))\n",
    "\n",
    "  for i in range(1, len(weights) - 1):\n",
    "    z = np.dot(activations[i - 1], weights[i]) + biases[i]\n",
    "    activations.append(relu(z))\n",
    "\n",
    "  # last layer\n",
    "  zn = np.dot(activations[-1], weights[-1]) + biases[-1]\n",
    "  activations.append(sigmoid(zn))\n",
    "\n",
    "  return activations"
   ],
   "metadata": {
    "id": "EU9OYYCHR_jH"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loss functions"
   ],
   "metadata": {
    "id": "UMQeq9jm22Vz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def binary_cross_entropy_loss(y, y_hat):\n",
    "    return -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))"
   ],
   "metadata": {
    "id": "-KUvI7am22EZ"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def categorical_cross_entropy_loss(y, y_hat):\n",
    "  # both of shape (num_data_points, num_classes).\n",
    "  m = y.shape[0]\n",
    "  loss = -(1/m) * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat), axis=1)\n",
    "  loss = np.mean(loss)\n",
    "  return loss\n",
    "\n",
    "  # both of shape (num_classes,).\n",
    "  # return -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))"
   ],
   "metadata": {
    "id": "6yqsJZ3s6fqP"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Backward propagation"
   ],
   "metadata": {
    "id": "drtuuVwj8FSw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def back_prop(X, y, activations, weights):\n",
    "  m = X.shape[0]\n",
    "\n",
    "  dws = []\n",
    "  dbs = []\n",
    "\n",
    "  # last layer\n",
    "  dz = activations[-1] - y\n",
    "  dw = np.dot(activations[-2].T, dz) / m\n",
    "  db = np.sum(dz, axis=0, keepdims=True) / m\n",
    "  da = np.dot(dz, weights[-1].T)\n",
    "  dws.append(dw)\n",
    "  dbs.append(db)\n",
    "\n",
    "  for i in range(len(activations) - 2, -1, -1):\n",
    "    dz = da * (activations[i] > 0)\n",
    "    dw = np.dot(activations[i - 1].T, dz) / m\n",
    "    db = np.sum(dz, axis=0, keepdims=True) / m\n",
    "    da = np.dot(dz, weights[i].T)\n",
    "    dws.append(dw)\n",
    "    dbs.append(db)\n",
    "\n",
    "  dws.reverse()\n",
    "  dbs.reverse()\n",
    "\n",
    "  return dws, dbs"
   ],
   "metadata": {
    "id": "JKLjV5kM8LIJ"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Updating params"
   ],
   "metadata": {
    "id": "KEU5YBKMTMlY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def update_params(weights, biases, dws, dbs, learning_rate):\n",
    "  for i in range(len(weights)):\n",
    "    weights[i] -= learning_rate * dws[i]\n",
    "    biases[i] -= learning_rate * dbs[i]\n",
    "\n",
    "  return weights, biases"
   ],
   "metadata": {
    "id": "BqP7rziUTQWd"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training Functions (Putting All)"
   ],
   "metadata": {
    "id": "rQYSsSHHRazp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train(X, y, weights, biases, iterations=20000, learning_rate=0.05, loss=\"binary\", pr_int=1000):\n",
    "  loss_history = []\n",
    "  for i in range(iterations):\n",
    "    # forward propagations\n",
    "    activations = forward_prop(X, weights, biases)\n",
    "    yhat = activations[-1]\n",
    "\n",
    "    # backward propagation\n",
    "    dws, dbs = back_prop(X, y, activations, weights)\n",
    "\n",
    "    # update parameters\n",
    "    weights, biases = update_params(weights, biases, dws, dbs, learning_rate)\n",
    "\n",
    "    # compute loss\n",
    "    if loss == \"binary\":\n",
    "      iter_loss = binary_cross_entropy_loss(y, yhat)\n",
    "    elif loss == \"category\":\n",
    "      iter_loss = categorical_cross_entropy_loss(y, yhat)\n",
    "    loss_history.append(iter_loss)\n",
    "\n",
    "    # print loss every pr_int\n",
    "    if i % pr_int == 0:\n",
    "      print(f\"Loss after {i} iterations: {iter_loss}\")\n",
    "\n",
    "  return weights, biases, loss_history"
   ],
   "metadata": {
    "id": "TPoeubaYReCL"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Making Prediction"
   ],
   "metadata": {
    "id": "O49K8mw-bf8g"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def predict(X, weights, biases):\n",
    "  activations = forward_prop(X, weights, biases)\n",
    "  return (activations[-1] > 0.5).astype(int)"
   ],
   "metadata": {
    "id": "Pfuyh3NabepV"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training Testing"
   ],
   "metadata": {
    "id": "zwYFEJopcKlu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Input dataset\n",
    "X = np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "    \n",
    "# Output dataset            \n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])"
   ],
   "metadata": {
    "id": "J3Vu4lU2cKJU"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# initialize weights and biases\n",
    "layers = [10, 10]\n",
    "weights, biases = initialize_weights_and_biases(X, out_layer=1, layers=layers, p=True)\n",
    "\n",
    "# train network\n",
    "weights, biases, loss_history = train(X, y, weights, biases, iterations=600, learning_rate=0.05, loss=\"binary\", pr_int=100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDyaPQrlcVFT",
    "outputId": "3add4bfe-cd2c-4636-d803-63b96c2e2841"
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Shape\n",
      "(3, 10)\n",
      "(10, 10)\n",
      "(10, 1)\n",
      "-------\n",
      "Biases Shape\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "(1, 1)\n",
      "Loss after 0 iterations: 0.7364883671371185\n",
      "Loss after 100 iterations: 0.6342072537103294\n",
      "Loss after 200 iterations: 0.5677173982737228\n",
      "Loss after 300 iterations: 0.46085605966525467\n",
      "Loss after 400 iterations: 0.3294597819187775\n",
      "Loss after 500 iterations: 0.22516870747693993\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Accuracy calculation"
   ],
   "metadata": {
    "id": "g1JAxSAimiC6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def accuracy(y, y_hat):\n",
    "  return np.mean(y == y_hat)"
   ],
   "metadata": {
    "id": "pFBO2Rrumyae"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with MNIST Data"
   ],
   "metadata": {
    "id": "GvzVYfscnm6r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Load the MNIST dataset from OpenML\n",
    "mnist = fetch_openml(name='mnist_784', version=1, data_home=None)\n",
    "o_X, o_y = mnist['data'], mnist['target']\n",
    "\n",
    "# Convert the target labels to integers\n",
    "o_y = o_y.astype(int)"
   ],
   "metadata": {
    "id": "kKH2NwfO55Dt"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Select only two classes, for example class 0 and class 1\n",
    "class_0 = np.where(o_y == 0)[0]\n",
    "class_1 = np.where(o_y == 1)[0]\n",
    "selected_classes = np.concatenate([class_0, class_1])"
   ],
   "metadata": {
    "id": "8XquwjNZ_tic"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = np.take(o_X, selected_classes, 0), np.take(o_y, selected_classes, 0)"
   ],
   "metadata": {
    "id": "7rtFf_Ln_83F"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Preprocess data\n",
    "X = np.array(X) / 255\n",
    "\n",
    "# lets check only 1 number\n",
    "y = np.array(y).reshape(-1, 1)"
   ],
   "metadata": {
    "id": "DWc7fzz3Bok3"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Balance the training dataset using random under-sampling\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "id": "0glGWc7n-0Wl"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_train.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_iDzOpynl9Y",
    "outputId": "4a4adaac-ccb6-4461-9f22-ef4bb08c21a6"
   },
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(11118, 1)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(11118, 784)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# initialize weights and biases\n",
    "layers = [128, 64]\n",
    "weights, biases = initialize_weights_and_biases(X_train, out_layer=1, layers=layers, p=True)\n",
    "\n",
    "# train network\n",
    "weights, biases, loss_history = train(X_train, y_train, weights, biases, iterations=500, learning_rate=0.05, loss=\"binary\", pr_int=100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvDBg9PlpGis",
    "outputId": "34cc2ff0-72fa-47ca-f91f-90222ecf83a3"
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Shape\n",
      "(784, 128)\n",
      "(128, 64)\n",
      "(64, 1)\n",
      "-------\n",
      "Biases Shape\n",
      "(1, 128)\n",
      "(1, 64)\n",
      "(1, 1)\n",
      "Loss after 0 iterations: 0.7121484957307843\n",
      "Loss after 100 iterations: 0.40430385172320576\n",
      "Loss after 200 iterations: 0.32893660332640134\n",
      "Loss after 300 iterations: 0.2768939966778561\n",
      "Loss after 400 iterations: 0.5154090661254944\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# make predictions\n",
    "train_predictions = predict(X_train, weights, biases)\n",
    "test_predictions = predict(X_test, weights, biases)"
   ],
   "metadata": {
    "id": "0f12gPCfpXnZ"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_acc = accuracy(y_train, train_predictions)\n",
    "test_acc = accuracy(y_test, test_predictions)\n",
    "\n",
    "print(\"Train accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgivsG8Hy_0u",
    "outputId": "ec137f51-87de-4fa4-e8f5-b6e9cc107559"
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8298255081849254\n",
      "Test accuracy:  0.8315290933694182\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "(test_predictions == 1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzs8K-BozAdi",
    "outputId": "b1066bd7-588e-4c75-9f27-b08be90e8daf"
   },
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ True],\n       [False],\n       [ True],\n       ...,\n       [ True],\n       [ True],\n       [ True]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "(y_test == 1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pof0AUP50hYW",
    "outputId": "eeefbf0c-4006-4eeb-9517-0c16070350ba"
   },
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ True],\n       [False],\n       [ True],\n       ...,\n       [ True],\n       [ True],\n       [ True]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "USgq8SugGLd5"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
